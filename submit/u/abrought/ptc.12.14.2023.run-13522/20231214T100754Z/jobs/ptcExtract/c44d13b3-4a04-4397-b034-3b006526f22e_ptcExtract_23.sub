universe=vanilla
should_transfer_files=YES
when_to_transfer_output=ON_EXIT_OR_EVICT
transfer_output_files=""
transfer_executable=False
getenv=True
on_exit_hold=ExitBySignal == true
on_exit_hold_reason=strcat("Job raised a signal ", string(ExitSignal), ". ", "Handling signal as if job has gone over memory limit.")
on_exit_hold_subcode=34
request_cpus=1
request_memory=2048
executable=$ENV(CTRL_MPEXEC_DIR)/bin/pipetask
arguments=--long-log --log-level=VERBOSE run-qbb /repo/ir2 /sdf/home/a/abrought/run6/submit/u/abrought/ptc.12.14.2023.run-13522/20231214T100754Z/u_abrought_ptc.12.14.2023.run-13522_20231214T100754Z.qgraph --qgraph-node-id c44d13b3-4a04-4397-b034-3b006526f22e 
output=jobs/ptcExtract/c44d13b3-4a04-4397-b034-3b006526f22e_ptcExtract_23.$(Cluster).out
error=jobs/ptcExtract/c44d13b3-4a04-4397-b034-3b006526f22e_ptcExtract_23.$(Cluster).err
log=jobs/ptcExtract/c44d13b3-4a04-4397-b034-3b006526f22e_ptcExtract_23.$(Cluster).log
+bps_job_quanta = "ptcExtract:1"
+bps_job_name = "c44d13b3-4a04-4397-b034-3b006526f22e_ptcExtract_23"
+bps_job_label = "ptcExtract"
+bps_isjob = "True"
+bps_project = "dev"
+bps_campaign = "quick"
+bps_run = "u_abrought_ptc.12.14.2023.run-13522_20231214T100754Z"
+bps_operator = "abrought"
+bps_payload = "ptc.12.14.2023.run-13522"
+bps_runsite = "s3df"
+bps_wms_service = "lsst.ctrl.bps.htcondor.htcondor_service.HTCondorService"
+bps_wms_workflow = "lsst.ctrl.bps.htcondor.htcondor_service.HTCondorWorkflow"
+bps_run_quanta = "ptcIsr:71;ptcExtract:1;ptcSolve:1;ptcPlot:1"
+bps_job_summary = "ptcIsr:71;ptcExtract:1;ptcSolve:1;ptcPlot:1;pipetaskInit:1;finalJob:1"
queue
