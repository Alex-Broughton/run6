universe=vanilla
should_transfer_files=YES
when_to_transfer_output=ON_EXIT_OR_EVICT
transfer_output_files=""
transfer_executable=True
getenv=True
on_exit_hold=ExitBySignal == true
on_exit_hold_reason=strcat("Job raised a signal ", string(ExitSignal), ". ", "Handling signal as if job has gone over memory limit.")
on_exit_hold_subcode=34
request_cpus=1
request_memory=2048
concurrency_limit=db_limit
executable=final_job.bash
arguments=/sdf/home/a/abrought/run6/submit/u/abrought/ptc.12.14.2023.run-13538.v4/20231215T084033Z/u_abrought_ptc.12.14.2023.run-13538.v4_20231215T084033Z.qgraph /repo/ir2
output=jobs/finalJob/finalJob.$(Cluster).out
error=jobs/finalJob/finalJob.$(Cluster).err
log=jobs/finalJob/finalJob.$(Cluster).log
+bps_job_quanta = ""
+bps_job_name = "finalJob"
+bps_job_label = "finalJob"
+bps_isjob = "True"
+bps_project = "dev"
+bps_campaign = "quick"
+bps_run = "u_abrought_ptc.12.14.2023.run-13538.v4_20231215T084033Z"
+bps_operator = "abrought"
+bps_payload = "ptc.12.14.2023.run-13538.v4"
+bps_runsite = "s3df"
+bps_wms_service = "lsst.ctrl.bps.htcondor.htcondor_service.HTCondorService"
+bps_wms_workflow = "lsst.ctrl.bps.htcondor.htcondor_service.HTCondorWorkflow"
+bps_run_quanta = "ptcSolve:1;ptcPlot:1"
+bps_job_summary = "ptcSolve:1;ptcPlot:1;pipetaskInit:1;finalJob:1"
queue
